{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "963mHeBuo0fX",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-f28464b407d5dec7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# Setup Instructions\n",
        "\n",
        "This notebook requires few things before you start:\n",
        "1. **Dataset**\n",
        "2. **Compiled test code** (`special_functions.cpython-312.pyc`)\n",
        "3. **The python version should be** `3.12.x`\n",
        "\n",
        "They will be automatically downloaded in the next cell.\n",
        "\n",
        "If the download fails for any reason:\n",
        "- You can download the files manually to your computer with the link below.  \n",
        "- Then upload them into Colab using the **Upload to Session Storage**.  \n",
        "- Make sure that:\n",
        "  - The dataset is placed in a folder called `data/`\n",
        "  - The compiled test code is placed inside a folder called `__pycache__/`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SgTs9fNwPB2D"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: wget\n",
            "Archive:  __pycache__.zip\n",
            "   creating: __pycache__\n",
            "  inflating: __pycache__/special_functions.cpython-312.pyc  \n",
            "zsh:1: command not found: wget\n"
          ]
        }
      ],
      "source": [
        "# Download test code\n",
        "!wget -O __pycache__.zip \"https://kth-my.sharepoint.com/:u:/g/personal/haotianq_ug_kth_se/EQ5EmlG2qP5DhRr9e9PKYZ8BWuhCPA34FIifFKCUK_BK_A?e=Gp1jXc&download=1\"\n",
        "!unzip __pycache__.zip\n",
        "\n",
        "# Download dataset\n",
        "!wget -O data.zip \"https://kth-my.sharepoint.com/:u:/g/personal/haotianq_ug_kth_se/EYHf_bkJRN5CgrMtKacEr7sBlSDK63WvgQ76xB4N_FWqkg?e=ReixTF&download=1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M8CTSillUgb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python version is OK: 3.12.11\n"
          ]
        }
      ],
      "source": [
        "import importlib.util, sys\n",
        "\n",
        "if sys.version_info.major == 3 and sys.version_info.minor == 12:\n",
        "    print(\"Python version is OK:\", sys.version.split()[0])\n",
        "else:\n",
        "    print(\"Python version is NOT 3.12.x, found:\", sys.version.split()[0])\n",
        "\n",
        "spec = importlib.util.spec_from_file_location(\n",
        "    \"special_functions\",\n",
        "    \"__pycache__/special_functions.cpython-312.pyc\"\n",
        ")\n",
        "module = importlib.util.module_from_spec(spec)\n",
        "sys.modules[\"special_functions\"] = module\n",
        "spec.loader.exec_module(module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCHNKFLxo0fY",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-f17509406aa4acd8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Name and birthday"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJgQyduHo0fY",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-1c262d632cd4c2f9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Fill in your name, birthday, and *run* the code below.** The birthday should be of the format YYYY-MM-DD. It is important that it is correct, as we will use it to fix the random seed later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UEwgkvcNo0fY"
      },
      "outputs": [],
      "source": [
        "student_name = \"Rios_Omar\"\n",
        "student_birthday = \"2000-05-24\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZmrMjoWo0fZ",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-1206c4480bd7fccc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# Assignment 1: Synthesis problems and synthesis principles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KaZElBxo0fZ",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-217159bd216ee20d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "In this assignment, you will complete a few tasks that will introduce you to some of the basic synthesis problems and synthesis principles that we have discussed in the lecture. Hopefully, we will see some of the concepts from lecture 1 in practice. Begin by importing the required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8RGvnLtOoPV",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-de7f858545fcf878",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "from special_functions import * # <- TODO MAY NEED TO CHANGE NAME DEPENDING ON FILE NAME\n",
        "import os\n",
        "import csv\n",
        "import torch\n",
        "import torchvision\n",
        "import random\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "birthday_int = int(student_birthday.replace(\"-\", \"\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQlChHeLo0fZ",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-aae8315882420831",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = \"data.zip\"\n",
        "\n",
        "if os.path.exists(zip_path):\n",
        "    extract_to = os.path.splitext(zip_path)[0]\n",
        "    os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "    # Extract all files\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "    print(f\"Files extracted to {extract_to}\")\n",
        "else:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxOwLsxvOpFo",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-86c325594b61bc20",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPPMssbNo0fZ",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-03a720b28f2c8645",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Now, let us load and visualise our data. In this exercise, we will be using the CelebA dataset, which contains 202,599 images of celebrities. The dataset is already partitioned into training, validation (evaluation), and test sets. Moreover, the CelebA dataset includes attribute labels for each image, making it easier to filter the images if we want or have the need to. For example, some of the attributes indicate whether the celebrity is wearing glasses, has a beard, is smiling, or is bald.\n",
        "\n",
        "We will load the data using the PyTorch DataLoader approach. Doing it this way not only allows us to shuffle the data efficiently, but also enables us to load the data in batches. Batch loading will be crucial for later parts of the course, as it allows for parallel processing on GPUs, speeding up computation when we deal with more complicated models later on. Therefore, while this approach is not strictly necessary in this exercise (as we will see), it is good to be familiar with it already.\n",
        "\n",
        "First, we will create the class that will handle loading and preprocessing each image in the dataset. Then, we will wrap it with a PyTorch DataLoader. The first cell below is the class. The second cell instantiate our dataset into two sets: a validation and a training set, before wrapping them around dataloaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dkS2wT8Hmz4",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-ccb85619ed1365de",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "class CelebADataset(Dataset):\n",
        "    def __init__(self, data_dir, attr_file=None, bbox_file=None, eval_file=None, partition=None,\n",
        "                 transform=None, filter_attrs=None, keep_percentage=1.0):\n",
        "        \"\"\"\n",
        "        Custom dataset for CelebA with optional filtering.\n",
        "\n",
        "        Parameters:\n",
        "        - data_dir (str): Path to the image directory.\n",
        "        - attr_file (str or None): Path to the attributes CSV. If None, no attribute filtering is applied.\n",
        "        - bbox_file (str or None): Path to the bounding box CSV. If None, no cropping is applied.\n",
        "        - eval_file (str or None): Path to the evaluation partition CSV. If None, all images are used.\n",
        "        - partition (int or None): Dataset partition to use (0=train, 1=eval, 2=test). If None, all partitions are used.\n",
        "        - transform (torchvision.transforms): Image transformations.\n",
        "        - filter_attrs (dict or None): Attributes to filter. Example: {'Smiling': 1, 'Eyeglasses': 1}\n",
        "        - keep_percentage (float): Fraction of selected images to keep (0.0 to 1.0).\n",
        "        \"\"\"\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Load partition data if specified\n",
        "        all_images = set(os.listdir(data_dir))\n",
        "        if eval_file and partition is not None:\n",
        "            partition_data = self._load_partition_data(eval_file)\n",
        "            all_images = {img for img, part in partition_data.items() if part == partition}\n",
        "\n",
        "        # Load bounding boxes if provided\n",
        "        self.bbox_data = self._load_bbox_data(bbox_file) if bbox_file else {}\n",
        "\n",
        "        # Load and filter attributes if provided\n",
        "        if attr_file and filter_attrs:\n",
        "            attr_data = self._load_attr_data(attr_file)\n",
        "            self.image_files = [\n",
        "                img for img in all_images if all(attr_data.get(img, {}).get(attr, 0) == value for attr, value in filter_attrs.items())\n",
        "            ]\n",
        "        else:\n",
        "            self.image_files = list(all_images)  # Use all images if no filtering\n",
        "\n",
        "        # Apply percentage filtering\n",
        "        total_images = len(self.image_files)\n",
        "        keep_size = int(total_images * keep_percentage)\n",
        "        self.image_files = self.image_files[:keep_size]\n",
        "\n",
        "    def _load_partition_data(self, eval_file):\n",
        "        \"\"\"Loads partition data from the evaluation CSV.\"\"\"\n",
        "        partition_data = {}\n",
        "        with open(eval_file, 'r') as f:\n",
        "            reader = csv.reader(f)\n",
        "            next(reader)  # Skip header\n",
        "\n",
        "            for row in reader:\n",
        "                img_name, part = row[0], int(row[1])\n",
        "                partition_data[img_name] = part\n",
        "\n",
        "        return partition_data\n",
        "\n",
        "    def _load_bbox_data(self, bbox_file):\n",
        "        \"\"\"Loads bounding box data from a CSV file.\"\"\"\n",
        "        bbox_data = {}\n",
        "        with open(bbox_file, 'r') as f:\n",
        "            reader = csv.reader(f)\n",
        "            next(reader)  # Skip header\n",
        "\n",
        "            for row in reader:\n",
        "                img_name, x, y, w, h = row[0], int(row[1]), int(row[2]), int(row[3]), int(row[4])\n",
        "                bbox_data[img_name] = {'x': x, 'y': y, 'w': w, 'h': h}\n",
        "\n",
        "        return bbox_data\n",
        "\n",
        "    def _load_attr_data(self, attr_file):\n",
        "        \"\"\"Loads attribute data from a CSV file.\"\"\"\n",
        "        attr_data = {}\n",
        "        with open(attr_file, 'r') as f:\n",
        "            reader = csv.reader(f)\n",
        "            header = next(reader)[1:]  # Get attribute names (skip 'image_id')\n",
        "\n",
        "            for row in reader:\n",
        "                img_name = row[0]\n",
        "                attr_values = [int(x) for x in row[1:]]  # Convert attributes to int (-1 or 1)\n",
        "                attr_data[img_name] = {header[i]: attr_values[i] for i in range(len(header))}\n",
        "\n",
        "        return attr_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_files[idx]\n",
        "        img_path = os.path.join(self.data_dir, img_name)\n",
        "\n",
        "        # Load image\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Apply bounding box cropping if bbox data is available\n",
        "        if img_name in self.bbox_data:\n",
        "            bbox = self.bbox_data[img_name]\n",
        "            x, y, w, h = bbox['x'], bbox['y'], bbox['w'], bbox['h']\n",
        "\n",
        "            # Ensure bounding box coordinates are within image size\n",
        "            image = image.crop((x, y, x + w, y + h))\n",
        "\n",
        "        # Apply transformations\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruU3y6-ZQKW1",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-a1c8d58b52e65dcb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "pixel_dim = 64\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.CenterCrop(140),\n",
        "    transforms.Resize((pixel_dim, pixel_dim)),  #\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Create train dataset with the images:\n",
        "dataset = CelebADataset(\n",
        "    data_dir='data/img_align_celeba/img_align_celeba',\n",
        "    attr_file='data/list_attr_celeba.csv',\n",
        "    bbox_file=None,  # Set to None to disable cropping\n",
        "    eval_file='data/list_eval_partition.csv',\n",
        "    partition=0,  # Use train set (0=train, 1=eval, 2=test)\n",
        "    transform=transform,\n",
        "    filter_attrs={},\n",
        "    keep_percentage=0.02 # TODO -> CHANGE THIS! (0.002 = 325 images)\n",
        ")\n",
        "\n",
        "# Create a DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Create evaluation dataset with the images:\n",
        "dataset_eval = CelebADataset(\n",
        "    data_dir='data/img_align_celeba/img_align_celeba',\n",
        "    attr_file='data/list_attr_celeba.csv',\n",
        "    bbox_file=None,  # Set to None to disable cropping\n",
        "    eval_file='data/list_eval_partition.csv',\n",
        "    partition=1,  # Use train set (0=train, 1=eval, 2=test)\n",
        "    transform=transform,\n",
        "    filter_attrs={},\n",
        "    keep_percentage=0.1 # TODO -> CHANGE THIS!\n",
        ")\n",
        "\n",
        "# Create a DataLoader for the evaluation images\n",
        "dataloader_eval = DataLoader(dataset_eval, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBc42B7bo0fa",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-02118b96d399d45e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "The batchsize of each dataloader is 64, meaning that each batch contains 64 images. Notice how we have transformed each image into 64x64 pixels by first centring the image and then cropping them (see the transform we have defined). Each image therefore contains 64x64x3 pixel values: 64x64 pixels with 3 RGB channels.\n",
        "\n",
        "Now that we have initialised the dataset and created the dataloader, let's display some of our images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd1xVrbbQAs3",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-b70ca359484b6067",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Verify the dataset\n",
        "# Get a batch of images\n",
        "data_iter = iter(dataloader)\n",
        "images = next(data_iter)\n",
        "\n",
        "# Display the images\n",
        "grid_img = torchvision.utils.make_grid(images, nrow=8)\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.imshow(grid_img.permute(1, 2, 0))\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hozzNvTJo0fa",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-ab8a217be3a7488c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "In our current implementation, each image is a PyTorch tensor with shape (3, 64, 64). For this exercise, however, we will mostly be using the Scikit-Learn library. Many of the built-in functions in Scikit-Learn requires the data to be in numpy arrays rather than PyTorch tensors. The cell below transforms our train and validation datasets into numpy arrays. The variables `dataset_np` and `evalset_np`, which are the two datasets we will primarily work on, are the resulting data in numpy arrays. Make sure you understand what is happening, as it will greatly aid understanding for later tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0cPn4V6o0fa",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-7a3b84a88f520327",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "dataset_np = []\n",
        "evalset_np = []\n",
        "\n",
        "for batch in dataloader:\n",
        "    # batch has shape [batch_size, 3, 64, 64]\n",
        "    dataset_np.append(batch)\n",
        "\n",
        "for batch in dataloader_eval:\n",
        "    evalset_np.append(batch)\n",
        "\n",
        "# Make it so everything is fit along sample dimension\n",
        "# shape: [n_images, 3, 64, 64]\n",
        "dataset_np = torch.cat(dataset_np, dim=0)\n",
        "evalset_np = torch.cat(evalset_np, dim=0)\n",
        "\n",
        "# Transforms the pyTorch tensors the numpy arrays.\n",
        "dataset_np = dataset_np.numpy()\n",
        "evalset_np = evalset_np.numpy()\n",
        "\n",
        "# Transpose to RGB-last for image flattening\n",
        "# shape: [n_images, 64, 64, 3]\n",
        "dataset_np = dataset_np.transpose(0, 2, 3, 1)\n",
        "evalset_np = evalset_np.transpose(0, 2, 3, 1)\n",
        "\n",
        "# Final flattening\n",
        "# shape: (n_images, 12288)\n",
        "dataset_np = dataset_np.reshape(dataset_np.shape[0], -1)\n",
        "evalset_np = evalset_np.reshape(evalset_np.shape[0], -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "187ZOofGo0fa",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-7168a533a2593d8d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Now that we have transformed our data into the required shape and format, we are ready to begin! Good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-R4rUgxo0fa",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-a28c45af28b8de44",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 1.1 Mass covering and mode collapse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkVhL38Io0fa",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-007878713e84afcc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "We’ll begin this exercise with a simple game. The first cell implements a Gaussian Mixture Model (GMM) with variance flooring (try to think about why this may be useful?). Although scikit-learn offers a GMM implementation, it doesn’t include variance flooring by default.\n",
        "\n",
        "Below that, the second cell implements three different models for generating face images.<br/>\n",
        "Model A: samples directly from the original training dataset.<br/>\n",
        "Model B: samples from a GMM fitted to the entire training dataset.<br/>\n",
        "Model C: samples from a GMM fitted to only a few faces and with a low number of GMM-components.<br/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAaLMsM0o0fa",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-951118549eebf9a8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.mixture._gaussian_mixture import _estimate_gaussian_parameters\n",
        "from sklearn.mixture._gaussian_mixture import _compute_precision_cholesky\n",
        "\n",
        "class GaussianMixtureWithVarianceFloor(GaussianMixture):\n",
        "    \"\"\"\n",
        "    GaussianMixture subclass that applies variance flooring during the M-step.\n",
        "    Only supports diagonal covariance type.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_components=1,\n",
        "        covariance_type=\"diag\",\n",
        "        tol=1e-3,\n",
        "        reg_covar=1e-6,\n",
        "        max_iter=100,\n",
        "        n_init=1,\n",
        "        init_params=\"kmeans\",\n",
        "        weights_init=None,\n",
        "        means_init=None,\n",
        "        precisions_init=None,\n",
        "        random_state=None,\n",
        "        warm_start=False,\n",
        "        verbose=0,\n",
        "        verbose_interval=10,\n",
        "        variance_floor=1e-3\n",
        "    ):\n",
        "        super().__init__(\n",
        "            n_components=n_components,\n",
        "            covariance_type=covariance_type,\n",
        "            tol=tol,\n",
        "            reg_covar=reg_covar,\n",
        "            max_iter=max_iter,\n",
        "            n_init=n_init,\n",
        "            init_params=init_params,\n",
        "            weights_init=weights_init,\n",
        "            means_init=means_init,\n",
        "            precisions_init=precisions_init,\n",
        "            random_state=random_state,\n",
        "            warm_start=warm_start,\n",
        "            verbose=verbose,\n",
        "            verbose_interval=verbose_interval\n",
        "        )\n",
        "        self.variance_floor = variance_floor\n",
        "\n",
        "    def _m_step(self, X, log_resp):\n",
        "        \"\"\"M step.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "\n",
        "        log_resp : array-like of shape (n_samples, n_components)\n",
        "            Logarithm of the posterior probabilities (or responsibilities) of\n",
        "            the point of each sample in X.\n",
        "        \"\"\"\n",
        "        self.weights_, self.means_, self.covariances_ = _estimate_gaussian_parameters(\n",
        "            X, np.exp(log_resp), self.reg_covar, self.covariance_type\n",
        "        )\n",
        "        self.weights_ /= self.weights_.sum()\n",
        "\n",
        "        if self.covariance_type == \"diag\":\n",
        "          self.covariances_ = np.maximum(self.covariances_, self.variance_floor)\n",
        "        else:\n",
        "           raise ValueError(\"GaussianMixtureWithVarianceFloor only supports 'diag' covariance_type.\")\n",
        "\n",
        "        self.precisions_cholesky_ = _compute_precision_cholesky(\n",
        "            self.covariances_, self.covariance_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Fo5Pxj3o0fa",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-dece543b7b864775",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def model_A(dataset, num_images=5):\n",
        "    max_idx = dataset.shape[0]\n",
        "    idx = [random.randint(0, max_idx - 1) for _ in range(num_images)]  # random indices\n",
        "\n",
        "    plt.figure(figsize=(num_images * 3, 3))\n",
        "    for i, image_idx in enumerate(idx):\n",
        "        img = dataset[image_idx].reshape(64, 64, 3)  # picks image directly from dataset and reshape to (H, W, C) for display\n",
        "\n",
        "        plt.subplot(1, num_images, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "\n",
        "def model_B(dataset, num_images=5):\n",
        "    # Fit and sample GMM\n",
        "    gmm = GaussianMixtureWithVarianceFloor(n_components=10, covariance_type = \"diag\", variance_floor=0.01)\n",
        "    gmm.fit(dataset)\n",
        "\n",
        "    samples, _ = gmm.sample(num_images)\n",
        "\n",
        "\n",
        "    # Plot the sampled images\n",
        "    plt.figure(figsize=(num_images * 3, 3))\n",
        "    for i in range(num_images):\n",
        "\n",
        "        # Reshape to image format\n",
        "        img = samples[i].reshape(64, 64, 3)\n",
        "        img = np.clip(img, 0, 1)\n",
        "\n",
        "        plt.subplot(1, num_images, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "\n",
        "def model_C(dataset, num_training_img=3, num_images=5):\n",
        "    max_idx = len(dataset)\n",
        "    idx = [random.randint(0, max_idx - 1) for _ in range(num_training_img)] # random indicies\n",
        "\n",
        "    dataset = dataset[idx] # random images from dataset\n",
        "\n",
        "    # Fit and sample GMM\n",
        "    gmm = GaussianMixtureWithVarianceFloor(n_components=num_training_img, covariance_type=\"diag\", variance_floor=0)\n",
        "    gmm.fit(dataset)\n",
        "\n",
        "    samples, _ = gmm.sample(num_images)\n",
        "\n",
        "    # Plot the sampled images\n",
        "    plt.figure(figsize=(num_images * 3, 3))\n",
        "    for i in range(num_images):\n",
        "\n",
        "        # Reshape to image format\n",
        "        samples_img = samples.reshape(num_images, 64, 64, 3)\n",
        "        samples_img = np.clip(samples_img, 0, 1)\n",
        "\n",
        "        plt.subplot(1, num_images, i + 1)\n",
        "        plt.imshow(samples_img[i])\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDIpH_Gko0fb",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-5b41427e98750afa",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Task 1.1.1 (E)** <br/>\n",
        "Run the `interactive_game` function below. Adjust the `n_samples` parameter to decide how many samples to draw from each model. Start with `n_samples = 1` and gradually increase it and work your way up. Match each row to its generating model. In other words: write which model (A, B, or C) you think corresponds to row 1, 2 and 3.\n",
        "\n",
        "(Reminder of models: <br/>\n",
        "Model A: samples directly from the original training dataset.<br/>\n",
        "Model B: samples from a GMM fitted to the entire training dataset.<br/>\n",
        "Model C: samples from a GMM fitted to only a few faces and with a low number of GMM-components).<br/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA_BypEqo0fb",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-c4d9da763c79843c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "interactive_game(model_A, model_B, model_C, birthday_int, dataset_np, n_samples, GaussianMixtureWithVarianceFloor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oSfXBA4o0fb",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-585ed0a36ad00b1a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "When looking at the outputs, we can clearly see that one of the models (one of the rows) produces unnatural and blurry images, while another produces only a very narrow range of outputs – the same few images every time (don’t see it? Experiment more with the number of samples drawn).\n",
        "\n",
        "These models are good examples of mode collapse and mass-covering behaviour. The blurry and unrealistic images are samples from the model exhibiting **mass-covering**: it spreads its probability mass too widely, generating samples outside the true data distribution, resulting in blurry messes. Meanwhile, the model producing nearly identical images is showing **mode collapse**: it captures only a small subset of the data distribution, failing to represent it fully, resulting in the same few images being sampled."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDJOs7uLo0fb",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-c592096e5937df1a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Question 1.1.2 (E)** <br/>\n",
        "How many samples did *you* need to see (what value for `n_samples`) before you could identify which model corresponded to which row? Was it easier to identify the mass covering (too broad) or the mode collapsed (too narrow) model? Explain!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XzOTiZio0fb",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-97b4c4267688aa74",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "** STUDENT ANSWER HERE **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QoKetXso0fb",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-fe964566290add4a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Now, let us move on to two new models.\n",
        "\n",
        "This time, we have a completely untrained model, which simply samples from the standard normal distribution, and a model that has memorised a single image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2njoT9ro0fb",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-de40009c460b59bc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def sample_untrained():\n",
        "    sample = np.random.randn(64, 64, 3)\n",
        "    return sample\n",
        "\n",
        "def sample_memorised(mem_img, sigma=0.001):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "    - mem_img: The memorised image.\n",
        "    \"\"\"\n",
        "    mem_img = mem_img.reshape((64, 64, 3))\n",
        "    noise = sigma * np.random.randn(*mem_img.shape)\n",
        "    sample = mem_img + noise\n",
        "    return sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRLEeuklo0fb",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-2a74382ce2fcc13c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Of course, in order to utilise these models, we must must know how to sample from them.\n",
        "\n",
        "**Task 1.1.3 (E)** <br/>\n",
        "Sample from the untrained and memorised model. Store the sample from the memorised model in `memo_sample` and from the untrained model in `untr_sample`. Use `memo_img` as the memorised image and `sigma_memo` as the standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9h1DNRYo0fb",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-8c3fc53584530d83",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Set random seeds\n",
        "random.seed(birthday_int)\n",
        "np.random.seed(birthday_int)\n",
        "\n",
        "max_idx = dataset_np.shape[0]\n",
        "memo_img = dataset_np[random.randint(0, max_idx - 1)]   # Random memorised images\n",
        "sigma_memo = 0.03   # Stdev\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUVUT_4po0fb",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-a57f3a4c43c5118d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# PUT YOUR CODE HERE FOR TASK 1.1.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lxv7hEnFo0fb",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-ba038adea6b4ba0f",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    memo_sample\n",
        "    untr_sample\n",
        "except NameError:\n",
        "    print(\"NameError: Did you store you samples in memo_sample and untr_sample?\")\n",
        "\n",
        "### BEGIN HIDDEN TESTS\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufnv5L1Eo0fb",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-6957e68d80421c44",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Let us also see what exactly it was that we sampled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M909kKGqo0fc",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-e2d3ac4c198536a3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "#Reformats data to make it suitable for display\n",
        "memo_img_disp = memo_img.reshape((64, 64, 3))\n",
        "memo_img_disp = np.clip(memo_img_disp, 0, 1)\n",
        "memo_sample_disp = np.clip(memo_sample, 0, 1)\n",
        "untr_sample_disp = np.clip(untr_sample, 0, 1)\n",
        "\n",
        "\n",
        "#Dispalying images\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(memo_img_disp)\n",
        "plt.title(\"Original Memorised Image\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(memo_sample_disp)\n",
        "plt.title(\"Memorised Sample (with noise)\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(untr_sample_disp)\n",
        "plt.title(\"Untrained Sample\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2py9At4o0fc",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-00c029d30925f3ba",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Question 1.1.4 (E)** <br/>\n",
        "Which model generates the best-looking faces? Which model is too broad (mass covering) and which model is too narrow (mode collapse)? Motivate your answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdX7gXk1o0fc",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-750ce8ec119ed75e",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "** STUDENT ANSWER HERE **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2otknGW6o0fc",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-b0e8d4d2477916c1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "While the human eyes are great for many things, they are often not as fault-free as we would often like. Therefore, engineers and scientists often like numerical measures that try to capture some characteristic or property objectively.\n",
        "\n",
        "One way we could try to quantify how “good” or “bad” a sample is involves using log-likelihood as our objective measure of \"goodness\". Remember that log-likelihood provides a measure of how probable a given sample is according to the model’s learned distribution. It tells us how well the model explains or assigns probability mass to that particular data point. A higher log-likelihood indicates that the model considers the sample more plausible.\n",
        "\n",
        "**Task 1.1.5 (E)** <br/>\n",
        "Evaluate the log-likelihood for both models. For each model, calculate the mean of the log-likelihood over *all* of the images in our training dataset. Store the values of the mean log-likelihood for the memorised model in `ll_memo` and the value for the untrained model in `ll_untr`. You can use the pre-implemented `log_likelihood` function to calculate the log-likelihood."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j209DCnco0fc",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-e4cefabd32a99230",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def log_likelihood(x, mu, sigma):\n",
        "    \"\"\"\n",
        "    x: np array (H, W, C) - single image\n",
        "    mu: np array (H, W, C) - mean image\n",
        "    sigma: float - std deviation\n",
        "    \"\"\"\n",
        "    H, W, C = x.shape\n",
        "    D = H * W * C  # total dimensionality\n",
        "    diff = x - mu\n",
        "    sq_norm = np.sum(diff ** 2)\n",
        "\n",
        "    ll = - (D / 2) * np.log(2 * np.pi) \\\n",
        "         - (D / 2) * np.log(sigma ** 2) \\\n",
        "         - (1 / (2 * sigma ** 2)) * sq_norm\n",
        "\n",
        "    return ll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_j-ea_Ho0fc",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-0fbd88609d5108f9",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# PUT YOUR CODE HERE FOR TASK 1.1.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZh_gYnBo0fc",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-f5f6dc81c1de4d40",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    ll_memo\n",
        "    ll_untr\n",
        "except NameError:\n",
        "    print(\"Did you store the values in ll_memo and ll_untr?\")\n",
        "\n",
        "print(f\"Mean log likelihood of memorised model: {ll_memo}\")\n",
        "print(f\"Mean log likelihood of untrained  model: {ll_untr}\")\n",
        "\n",
        "### BEGIN HIDDEN TESTS\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX1v0K8go0fd",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-9970fb80a7b43b32",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Question 1.1.6 (E)** <br/>\n",
        "Which model has the highest log-likelihood? The one that is too broad or the one that is too narrow? Compare this with your observations in task and question 1.1.3 - 1.1.4. Was this what you expected? Did the log-likelihood agree with your personal observations using your eyes? Motivate your answer!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNM3fQBro0fd",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-06176fbda8510a9f",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "** STUDENT ANSWER HERE **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiV1gaLGo0fd",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-3522fc4915d614f8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "For now, let's return to Model B from Task 1.1.1. Recall that Model B is a GMM fit to the whole training dataset, producing samples with excess diversity and unrealistic, blurry outputs. In deep learning and machine learning in general, temperature is a parameter commonly used during sampling to control randomness and diversity (sometimes viewed as a simple \"hack\" to control the output).\n",
        "\n",
        "Now, we will turn to temperature next and explore how temperature affects the samples generated by this GMM model. First, we need to implement sampling with temperature, where the temperature is applied to scale the covariances of the Gaussians.\n",
        "\n",
        "**Task 1.1.7 (D)** <br/>\n",
        "Implement GMM sampling with temperature as a parameter. Your function should take **a fitted GMM**, **temperature** and **number of samples to be drawn** as inputs, and output the samples in a numpy array of the form `(n_samples, 64, 64, 3)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ct4Rs2pJo0fd",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-2dec9774a397da94",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def samples_with_temperature(gmm, temperature = 1, n_samples = 4):\n",
        "    \"\"\" Input:\n",
        "    -gmm: Fitted GMM\n",
        "    -temperature: the temperature\n",
        "    -n_samples: number of samples to be drawn.\n",
        "    Returns: Np array with samples in shape (n_samples, 64, 64, 3)\"\"\"\n",
        "\n",
        "    # PUT YOUR CODE HERE FOR TASK 1.1.7\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0Nyvprto0fd",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-8edce95fca3923a0",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    samples_with_temperature\n",
        "except NameError:\n",
        "    print(\"Not implemented\")\n",
        "\n",
        "gmm = GaussianMixtureWithVarianceFloor(n_components=5, covariance_type = \"diag\", variance_floor=0, random_state = birthday_int)\n",
        "gmm.fit(dataset_np)\n",
        "\n",
        "assert samples_with_temperature(gmm, 1, 4) is not None, \"Did you return the samples?\"\n",
        "assert np.allclose(samples_with_temperature(gmm, 1, 4), temp_sampling(gmm, 1, 4)), \"Error in implementation\"\n",
        "\n",
        "### BEGIN HIDDEN TESTS\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p38qxmt_o0fd",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-09b4edbe80179e39",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Now, let's draw some samples from our shiny newly implemented model.\n",
        "\n",
        "**Task 1.1.8 (E)** <br/>\n",
        "Generate samples with reduced sampling temperature from the already fitted GMM stored in `gmm`. You can use your own function or the pre-implemented `temp_sampling` (if you did not complete task 1.1.7), which takes the same parameters and returns the same output as a correctly implemented `samples_with_temperature`. Sample with temperatures 0.0, 0.25, and 0.5, and store these samples in `samples_0`, `samples_25`, and `samples_50` respectively. Generate **5 samples for each temperature**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Vs1UnNEo0fd",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-5a264b13fe74e398",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "np.random.seed(birthday_int)\n",
        "random.seed(birthday_int)\n",
        "\n",
        "gmm = GaussianMixtureWithVarianceFloor(n_components=10, covariance_type = \"diag\", variance_floor=0, random_state=birthday_int)\n",
        "gmm.fit(dataset_np)\n",
        "\n",
        "n_samples = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrwZMdl3o0fd",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-3943d2dd1aea30a2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# PUT YOUR CODE HERE FOR TASK 1.1.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2QYZUqzo0fd",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-ad96c823325e2516",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    samples_0\n",
        "    samples_25\n",
        "    samples_50\n",
        "except NameError:\n",
        "    print(\"NameError: Have you stored the samples in the correct variables?\")\n",
        "\n",
        "assert samples_0.shape[0] == 5 and samples_25.shape[0] == 5 and samples_50.shape[0] == 5, \"Did you draw 5 samples?\"\n",
        "\n",
        "### BEGIN HIDDEN TESTS\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axW_Ab8oo0fd",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-a8fefc18e7d4aefb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Finally, let's see what the images look like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SZwLwVYo0fd",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-9755a41c0a8e0fa7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Draw images\n",
        "samples_0 = samples_0.reshape(n_samples, 64, 64, 3)\n",
        "samples_0 = np.clip(samples_0, 0, 1)  # Clip values to valid range if needed\n",
        "\n",
        "fig1 = plt.figure(figsize=(15, 10))\n",
        "for i in range(n_samples):\n",
        "    plt.subplot(4, n_samples, i+1)\n",
        "    plt.imshow(samples_0[i])\n",
        "    plt.axis(\"off\")\n",
        "fig1.suptitle(\"T=\" + str(0), fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "samples_25 = samples_25.reshape(n_samples, 64, 64, 3)\n",
        "samples_25 = np.clip(samples_25, 0, 1)\n",
        "\n",
        "fig1 = plt.figure(figsize=(15, 10))\n",
        "for i in range(n_samples):\n",
        "    plt.subplot(4, n_samples, i+1)\n",
        "    plt.imshow(samples_25[i])\n",
        "    plt.axis(\"off\")\n",
        "fig1.suptitle(\"T=\" + str(0.25), fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "samples_50 = samples_50.reshape(n_samples, 64, 64, 3)\n",
        "samples_50 = np.clip(samples_50, 0, 1)\n",
        "\n",
        "fig1 = plt.figure(figsize=(15, 10))\n",
        "for i in range(n_samples):\n",
        "    plt.subplot(4, n_samples, i+1)\n",
        "    plt.imshow(samples_50[i])\n",
        "    plt.axis(\"off\")\n",
        "fig1.suptitle(\"T=\" + str(0.5), fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if71J0Ejo0fe",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-706834f30231408a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Question 1.1.9 (E)** <br/>\n",
        "How does the appearance of the faces change when you reduce the sampling temperature? Do you think the faces look better with a temperature close to 1 or close to 0? Motivate your answer!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylwF9xdeo0fe",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-5471f32f5c3b1bcf",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "** STUDENT ANSWER HERE **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcwrPdS5o0fe",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-1a40a8d14b34906b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 1.2 Oversmoothing and undersmoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTpqQinAo0fe",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-54e2adc6e2b25f30",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Next, we will move on to the concepts of oversmoothing and undersmoothing. When it comes to images, oversmoothing refers to the phenomenon where images become blurry and lose their fine details. Undersmoothing, on the other hand, is the reverse: images appear noisy and may contain too much, often unrealistic, detail. You probably already have an intuitive feeling for what undersmoothed and oversmoothed pictures look like, but to get a feel for this, let's sample some images to look at.\n",
        "\n",
        "This time, we will again sample from 3 different models.\n",
        "\n",
        "`data_sample`: A sample directly taken from the dataset.<br/>\n",
        "`mean_face`: The mean face of the dataset.<br/>\n",
        "`noisy_sample`: A sample from the data distribution with some added noise.<br/>\n",
        "\n",
        "(The astute amongst you will remember that `data_sample` is the same as model A from the previous task).\n",
        "\n",
        "First, let's implement these models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pg57O7EWo0fe",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-55616d0d3ce7ec56",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def data_sample(dataset, num_images=1):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "    - A list containing `num_images` images, each reshaped to (64, 64, 3)\n",
        "    \"\"\"\n",
        "    max_idx = dataset.shape[0]\n",
        "    idx = [random.randint(0, max_idx - 1) for _ in range(num_images)]  # random indices\n",
        "    images = []\n",
        "\n",
        "    for i, image_idx in enumerate(idx):\n",
        "        img = dataset[image_idx].reshape(64, 64, 3)\n",
        "        images.append(img)\n",
        "\n",
        "    return images\n",
        "\n",
        "def mean_face(dataset, num_images=1, sample_to_average=1000):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "    - A list containing `num_images` averaged images, each reshaped to (64, 64, 3)\n",
        "    \"\"\"\n",
        "    max_idx = dataset.shape[0]\n",
        "    images = []\n",
        "\n",
        "    for _ in range(num_images):\n",
        "        idx = np.random.choice(max_idx, sample_to_average, replace=True)\n",
        "        selected = dataset[idx]\n",
        "\n",
        "        # Compute mean across selected images\n",
        "        mean_face = np.mean(selected, axis=0)\n",
        "\n",
        "        images.append(mean_face.reshape(64, 64, 3))\n",
        "\n",
        "    return images\n",
        "\n",
        "\n",
        "def noisy_sample(dataset, num_images=1, sigma = 0.05):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "    - A list containing `num_images` noisy images, each reshaped to (64, 64, 3)\n",
        "    \"\"\"\n",
        "    max_idx = dataset.shape[0]\n",
        "    idx = [random.randint(0, max_idx - 1) for _ in range(num_images)]  # random indices\n",
        "    images = []\n",
        "\n",
        "    for i, image_idx in enumerate(idx):\n",
        "        img = dataset[image_idx].reshape(64, 64, 3)\n",
        "        noise = sigma * np.random.randn(*img.shape)\n",
        "        img = img + noise\n",
        "        images.append(img)\n",
        "\n",
        "    return images\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm5R479co0fe",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-0ef454dc05b46b00",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Now, we can sample from them to see what they produce:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytizgqpKo0fe",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-21ce683becbd12ae",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "np.random.seed(birthday_int)\n",
        "random.seed(birthday_int)\n",
        "\n",
        "img_q = data_sample(dataset_np, 3)\n",
        "img_x = mean_face(dataset_np, 3)\n",
        "img_y = noisy_sample(dataset_np, 3)\n",
        "\n",
        "# Clip all images before displaying\n",
        "img_q = [np.clip(img, 0, 1) for img in img_q]\n",
        "img_x = [np.clip(img, 0, 1) for img in img_x]\n",
        "img_y = [np.clip(img, 0, 1) for img in img_y]\n",
        "\n",
        "\n",
        "# Display images\n",
        "for row in range(3):\n",
        "    plt.figure(figsize=(9, 9))\n",
        "    plt.subplot(3, 3, row * 3 + 1)\n",
        "    plt.imshow(img_q[row])\n",
        "    plt.title(\"data_sample\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(3, 3, row * 3 + 2)\n",
        "    plt.imshow(img_x[row])\n",
        "    plt.title(\"mean_face\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(3, 3, row * 3 + 3)\n",
        "    plt.imshow(img_y[row])\n",
        "    plt.title(\"noisy_sample\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv21vzLfo0fe",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-3481a18204d8ba16",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "With the images in hand, let's try to again judge the images with our intuition and eyes.\n",
        "\n",
        "**Task 1.2.1 (E)** <br/>\n",
        "Look at each row. For each of the rows, order the images by smoothness from least to most smooth in the code cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sU6trkCo0fe",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-b24dda5b603f9658",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Answer format (example):\n",
        "most_smooth_r1 = \"data_sample\"\n",
        "middle_smooth_r1 = \"mean_face\"\n",
        "least_smooth_r1 = \"noisy_sample\"\n",
        "\"\"\"\n",
        "#PUT YOUR ANSWERS BELOW FOR TASK 1.2.1\n",
        "\n",
        "# Row 1:\n",
        "most_smooth_r1 = \"\"\n",
        "middle_smooth_r1 = \"\"\n",
        "least_smooth_r1 = \"\"\n",
        "\n",
        "# Row 2:\n",
        "most_smooth_r2 = \"\"\n",
        "middle_smooth_r2 = \"\"\n",
        "least_smooth_r2 = \"\"\n",
        "\n",
        "# Row 3:\n",
        "most_smooth_r3 = \"\"\n",
        "middle_smooth_r3 = \"\"\n",
        "least_smooth_r3 = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Da8UnTmo0fe",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-f428d8ee4e1c4c09",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Test your answers\n",
        "answers = [most_smooth_r1, most_smooth_r2, most_smooth_r3, middle_smooth_r1, middle_smooth_r2, middle_smooth_r3, most_smooth_r1, most_smooth_r2, most_smooth_r3]\n",
        "\n",
        "for answer in answers:\n",
        "    answer = answer.lower()\n",
        "    assert answer == \"data_sample\" or answer == \"mean_face\" or answer == \"noisy_sample\", \"Have you checked that your answering format is correct?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdLFd8-Eo0fe",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-81cf16f9f66bf34c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "While our eyes can perceive whether an image looks smooth or noisy, as we have discussed earlier, it can be very helpful to have a quantitative way to measure smoothness. It is for this purpose, that we will now implement a metric for smoothness. The metric is the standard deviation of pixel intensities in the luminosity (brightness) space of each image. Using luminosity will hopefully help us capture the amount of variation or “texture” in the image: a lower standard deviation in luminosity corresponds to a smoother, more uniform image, while a higher standard deviation indicates more noise or detail.\n",
        "\n",
        "**Task 1.2.2 (D)** <br/>\n",
        "Implement a measure of smoothness: the standard deviation in luminosity space. For luminosity, use the following formula:\n",
        "\n",
        "$L = 0.2126 * R + 0.7152 * G + 0.0722 * B$\n",
        "\n",
        "(Notice how the weights for red, green and blue is different? That is due to peculiarities in the human eyes, which are much more sensitive to green. This luminosity measure tries to capture that by placing a higher weight on green)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxQISRJCo0ff",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-f138d3881a2ac8a8",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def luminosity_std(img):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "    - img: A single image\n",
        "\n",
        "    Returns\n",
        "    - Our luminosity measure\n",
        "    \"\"\"\n",
        "    # PUT YOUR CODE HERE FOR TASK 1.2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeP5Roymo0ff",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-c229a81b1f41bdc3",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    luminosity_std\n",
        "except NameError:\n",
        "    print(\"Not Implemented\")\n",
        "\n",
        "# Test case 1\n",
        "test_img = np.ones((64, 64, 3))\n",
        "assert luminosity_std(test_img) == 0, \"Wrong implementation\"\n",
        "\n",
        "# Test case 2\n",
        "test_img = np.random.rand(64, 64, 3)\n",
        "assert luminosity_std(test_img) > 0, \"Wrong implementation\"\n",
        "\n",
        "# Test case 3 (half red half blue image)\n",
        "test_img = np.zeros((64, 64, 3))\n",
        "test_img[:32, :] = [1, 0, 0]\n",
        "test_img[32:, :] = [0, 0, 1]\n",
        "assert np.isclose(luminosity_std(test_img), 0.0702), \"Wrong implementation\"\n",
        "\n",
        "### BEGIN HIDDEN TESTS\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADQKa6sNo0ff",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-2674b18246732600",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Now, that we have our quantifiable measure, let's use our smoothness metric to evaluate the smoothness of the images produced by each model.\n",
        "\n",
        "**Task 1.2.3 (E)** <br/>\n",
        "Compute the average smoothness from 1000 samples. The samples are already drawn and stored in `img_a_1000`, `img_b_1000` and `img_c_1000`. You can use your own implementation or the already implemented function `calc_smoothness`(if you have not completed task 1.2.2), which functions exactly like a correctly implemented `luminosity_std`. Store the values in `smth_data_smpl`, `smth_mean_smpl` and `smth_noisy_smpl` respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6f3MDono0ff",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-517a9a66bb1fb275",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "np.random.seed(birthday_int)\n",
        "random.seed(birthday_int)\n",
        "\n",
        "n_samples = 1000\n",
        "img_a_1000 = data_sample(dataset_np, n_samples)\n",
        "img_b_1000 = mean_face(dataset_np, n_samples)\n",
        "img_c_1000 = noisy_sample(dataset_np, n_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znYF8wr-o0ff",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-478661b9794ff2e4",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Store the smoothness values in these variables.\n",
        "smth_data_smpl = 0 #data_sample\n",
        "smth_mean_smpl = 0 #mean_face\n",
        "smth_noisy_smpl = 0 #noisy sample\n",
        "\n",
        "# PUT YOUR CODE HERE FOR TASK 1.2.3\n",
        "\n",
        "print(\"data_sample smoothness: \" + str(smth_data_smpl))\n",
        "print(\"mean_face smoothness: \" + str(smth_mean_smpl))\n",
        "print(\"noisy_sample smoothness: \" + str(smth_noisy_smpl))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btw15Oeoo0ff",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-f6057f22ca939bdb",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "assert 1 > smth_mean_smpl > 0 and 1 > smth_mean_smpl > 0 and 1 > smth_noisy_smpl > 0\n",
        "assert smth_mean_smpl < smth_data_smpl and smth_mean_smpl < smth_noisy_smpl\n",
        "\n",
        "### BEGIN HIDDEN TESTS\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95SLC2lPo0ff",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-66860764d61605b6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Question 1.2.4 (E)** <br/>\n",
        "Does the standard deviation of luminosity as a measure of smoothness agree with your own opinion of smoothness for the three different models? Explain!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTgm5ufPo0ff",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-030ed13913a4644e",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": true
        }
      },
      "source": [
        "** STUDENT ANSWER HERE **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpJJfz8vo0ff",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-6e179b2e01532711",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Next, let's return to some of our models in section 1.1 as well as introduce a new model:  <br/>\n",
        "\n",
        "`gmm_sampling`: GMM fitted to the entire face dataset. <br/>\n",
        "`temp_sampling`: gmm_sampling but with reduced temperature. <br/>\n",
        "\n",
        "Notice how `gmm_sampling` is just our GMM model from task 1.1.1 and `temp_sampling` is just the our model from task 1.1.8 (return to these task if you need a refresher). Below, we have (re-)implemented `gmm_sampling`. For `temp_sampling`, we will call on that function just like we did in task 1.1.8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9HQS8Oro0ff",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-2408e38955fd90ec",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def gmm_sampling(dataset, num_images=5):\n",
        "    # Fit and sample GMM\n",
        "    gmm = GaussianMixtureWithVarianceFloor(n_components=10, covariance_type = \"diag\", variance_floor=0)\n",
        "    gmm.fit(dataset)\n",
        "\n",
        "    samples, _ = gmm.sample(num_images)\n",
        "\n",
        "    return samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yriYYG-o0ff",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-aab99e5094ff274d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Let's calculate the smoothness for samples from these two additional models. For this, we will set the temperature to 0.25."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZ9jkPhjo0ff",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-52161efc1dbc9dd4",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "np.random.seed(birthday_int)\n",
        "random.seed(birthday_int)\n",
        "\n",
        "temp = 0.25\n",
        "n_samples = 1000\n",
        "\n",
        "# Sampling from the models.\n",
        "img_gmm = gmm_sampling(dataset_np, n_samples)\n",
        "\n",
        "gmm = GaussianMixtureWithVarianceFloor(n_components=10, covariance_type = \"diag\", variance_floor=0)\n",
        "gmm.fit(dataset_np)\n",
        "img_temp = temp_sampling(gmm, temp, n_samples)\n",
        "\n",
        "# Reshapes arrays back to (n_samples, 64, 64, 3).\n",
        "img_gmm = img_gmm.reshape(-1, 64, 64, 3)\n",
        "img_temp = img_temp.reshape(-1, 64, 64, 3)\n",
        "\n",
        "# Calculate the average smoothness for each model\n",
        "smoothness_gmm = 0\n",
        "smoothness_temp = 0\n",
        "for i in range(n_samples):\n",
        "    smoothness_gmm += calc_smoothness(img_gmm[i])\n",
        "    smoothness_temp += calc_smoothness(img_temp[i])\n",
        "\n",
        "smoothness_gmm = smoothness_gmm / n_samples\n",
        "smoothness_temp = smoothness_temp / n_samples\n",
        "\n",
        "print(\"gmm_sampling smoothness: \" + str(smoothness_gmm))\n",
        "print(\"temp_sampling smoothness: \" + str(smoothness_temp))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEyORPNCo0ff",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-6e6562f2f3a5b693",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "And also: before we continue, let's sample some images so we can get a feel for the models and what they actually output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQX2GVn0o0fg",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-529ce12f313293ef",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Clip all images before displaying\n",
        "img_gmm = [np.clip(img, 0, 1) for img in img_gmm]\n",
        "img_temp = [np.clip(img, 0, 1) for img in img_temp]\n",
        "\n",
        "\n",
        "# Display images\n",
        "for row in range(1):\n",
        "    plt.figure(figsize=(9, 9))\n",
        "    plt.subplot(3, 3, row * 3 + 1)\n",
        "    plt.imshow(img_gmm[row])\n",
        "    plt.title(\"gmm_sampling\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(3, 3, row * 3 + 2)\n",
        "    plt.imshow(img_temp[row])\n",
        "    plt.title(\"temp_sampling\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM6sSXOGo0fg",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-2846ac1af3376c13",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Question 1.2.5 (E)** <br/>\n",
        "Are samples from `gmm_sampling` overly smooth? Explain. What about `temp_sampling`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPbQDpfeo0fg",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-83440a329ce9f555",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "** STUDENT ANSWER HERE **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNtuHrnso0fg",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-a36156658346b7c5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Question 1.2.6 (E)** <br/>\n",
        "Looking and analysing the results from above, is oversmoothing in this case the result from how the generative model was fit to the data, or how we sampled from it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrz8NlLio0fg",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-acccdf379bf06cc9",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "** STUDENT ANSWER HERE **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP_LucDeo0fg",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-d9ac6cef056b54c9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Question 1.2.7 (E)** <br/>\n",
        "Looking at the sampled images and the smoothness measure for the two models, does the standard deviation of luminosity as a measure of smoothness agree with your own opinion of smoothness? Explain!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7LH8SXvo0fg",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-67744aaf151c23d2",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "** STUDENT ANSWER HERE **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9Jwmt9lo0fg",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-558f31464e7bb0e6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Question 1.2.8 (E)** <br/>\n",
        "Please declare if you used any generative AI tools for solving this notebook, and if so which tools and roughly which parts you used them for. If you did not any generative AI tools, just answer \"None\". If you did use generative AI tools, also reflect in a sentence or two on how well it worked and what you learnt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO88YOlCo0fg",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-bfa9475eb6c0696f",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "** STUDENT ANSWER HERE **"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "GenerativeModels",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
